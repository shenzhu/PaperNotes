# An Introduction to Deep Learning 

## 1. Introduction
In statistical machine learning, a major issue is the selection of an appropriate **feature space** where input instances have desired properties for solving a particular problem.

The deep learning scheme: a **greedy unsupervised layer-wise pretraining stage** followed by a **superviesd fine-tuning stage** affecting all layers.

## 2. Types of deep learning models
- Deep learning with **RBMs**
	- Restricted Boltzmann Machines
	- Gaussian-Bernoulli RBM
	- stacked RBMs
- Stacked Auto-Associators
- Deep Kernel Machines
- Deep Convolutional Networks


*see the detail description of model in the paper*

## 3. Application domains for deep learning
Deep networks have been largely applied to **visual classification databases** such as handwritten digits, object categories, pedestrian detection or offroad robot navigation, and also on acoustic signals to perform audio classification. In **natural language processing**, a very interesting approach gives a proof that deep architectures can perform multi-task learning, giving state-of-the-art results on difficult tasks like **semantic role labeling**.

Another interesting application area is highly **nonlinear data compression**. **Reducing the dimensionality** of data has been presented as one of the first application of deep learning.

## 4. Open questions and future directions
*See this part in the paper*

## 5. Conclusion
Deep learning methods achieve very good accuracy, often the best one, for tasks where a large set of data is available, even if only **a small number** of instances are labeled.

## Location
***D:\Papers\ESANN.2011.Ludovic Arnold.md***

## Date
**2013.11.9**